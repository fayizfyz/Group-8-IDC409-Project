{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdtOl0NoQsoW"
      },
      "source": [
        "**Keyword Identification Squad: Group Members**\n",
        "\n",
        "\n",
        "1.   ANAS KP (MS21224)\n",
        "2.   INDRAJITH (MS21092)\n",
        "3.   FAYIZ M (MS21078)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Procedure**\n",
        "\n",
        "1. Inspect the data source\n",
        "2. Scrape HTML Content From IISER Pune webpage (Accessing IISER Mohali site was difficult due to security issues)\n",
        "4. Parse HTML Code With Beautiful Soup\n",
        "5. Store the data in SQLite database\n",
        "6. Perform analysis with words and digits.\n",
        "7. Plotted graph\n",
        "8. Visualization\n",
        "9. Error check and crosscheck using another small website (IISER Mohali Moodle website)"
      ],
      "metadata": {
        "id": "fV9dGTdIxcqF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZp7t06Nwtqj"
      },
      "outputs": [],
      "source": [
        "# Scraping HTML Contents from IISER Pune website (Main websites) and parsing the data\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "whole_data=''\n",
        "\n",
        "collected_urls = [\"https://www.iiserpune.ac.in/\",\n",
        "                  \"https://www.iiserpune.ac.in/institute/about\",\n",
        "                  \"https://www.iiserpune.ac.in/institute/people\",\n",
        "                  \"https://www.iiserpune.ac.in/institute/campus\",\n",
        "                  \"https://www.iiserpune.ac.in/admissionapplication\",\n",
        "                  \"https://www.iiserpune.ac.in/research\",\n",
        "                  \"https://www.iiserpune.ac.in/research/department/biology\",\n",
        "                  \"https://www.iiserpune.ac.in/research/department/chemistry\",\n",
        "                  \"https://www.iiserpune.ac.in/research/department/data-science\",\n",
        "                  \"https://www.iiserpune.ac.in/research/department/earth-and-climate-science\",\n",
        "                  \"https://www.iiserpune.ac.in/research/department/humanities-and-social-sciences\",\n",
        "                  \"https://www.iiserpune.ac.in/research/department/mathematics\",\n",
        "                  \"https://www.iiserpune.ac.in/research/department/physics\",\n",
        "                  \"https://www.iiserpune.ac.in/research/department/science-education\",\n",
        "                  \"https://www.iiserpune.ac.in/research/research-centres-and-initiatives\",\n",
        "                  \"https://www.iiserpune.ac.in/research/research-facilities\",\n",
        "                  \"https://www.iiserpune.ac.in/research/publications\",\n",
        "                  \"https://www.iiserpune.ac.in/news\",\n",
        "                  \"https://www.iiserpune.ac.in/events/\",\n",
        "                  \"https://www.iiserpune.ac.in/education\",\n",
        "                  \"https://www.iiserpune.ac.in/engage/outreach-and-training\",\n",
        "                  \"https://www.iiserpune.ac.in/engage/partnerships\",\n",
        "                  \"https://www.iiserpune.ac.in/library\",\n",
        "                  \"https://www.iiserpune.ac.in/opportunities\",\n",
        "                  ]\n",
        "\n",
        "for url in collected_urls:\n",
        "    page = requests.get(url, verify=False)\n",
        "    soup = BeautifulSoup(page.text, 'html.parser')\n",
        "    data = soup.get_text()\n",
        "    whole_data = whole_data + data\n",
        "    print(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting words and filtered the data (Removed conjunctions)\n",
        "import spacy\n",
        "from collections import Counter\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.max_length = 2000000\n",
        "new_data=whole_data.replace(\"\\u200e\", \" \")\n",
        "filtered_data=[]\n",
        "doc = nlp(new_data)\n",
        "\n",
        "# Extract and create a list of words\n",
        "alphabet_words = [token.text for token in doc if token.is_alpha]\n",
        "\n",
        "for word1 in alphabet_words:\n",
        "  sample=nlp.vocab[word1]\n",
        "  if sample.is_stop == False and len(word1)>1:\n",
        "    filtered_data.append(word1)\n",
        "\n",
        "print(\"Unfiltered_data: \",alphabet_words)\n",
        "print(\"Filtered_data: \",filtered_data)"
      ],
      "metadata": {
        "id": "Cj0YGIday1_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the data in Sqlite database\n",
        "\n",
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect('DATA_BANK.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "\n",
        "cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS Words (\n",
        "        id INTEGER PRIMARY KEY NOT NULL,\n",
        "        word TEXT NOT NULL\n",
        "    )\n",
        "''')\n",
        "\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "-opF51R03NA_"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conn = sqlite3.connect('DATA_BANK.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "\n",
        "for word in filtered_data:\n",
        "  cursor.execute(\"INSERT INTO Words (word) VALUES (?)\", (word,))\n",
        "\n",
        "\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "hP1wUCwcyBcl"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conn = sqlite3.connect('DATA_BANK.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute(\"SELECT word FROM Words\")\n",
        "\n",
        "keywords = cursor.fetchall()\n",
        "\n",
        "conn.close()\n",
        "\n",
        "for word in keywords:\n",
        "    print(word[0])"
      ],
      "metadata": {
        "id": "E7h8c7uYyHWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPwzJisUO4hu"
      },
      "outputs": [],
      "source": [
        "# Extract and create a list of numerical values and digits\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.max_length = 2000000\n",
        "doc = nlp(new_data)\n",
        "\n",
        "\n",
        "numericals_and_digits = [token.text for token in doc if token.is_digit]\n",
        "\n",
        "print(\"Numericals and Digits:\", numericals_and_digits)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unique words and sort them alphabetically\n",
        "unique = sorted(set(filtered_data))\n",
        "for unique_words in unique:\n",
        "    print(unique_words)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2pX7AcdA30AN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sorting words by their length\n",
        "length = sorted(set(filtered_data), key=len)\n",
        "for words_by_length in length:\n",
        "    print(words_by_length)"
      ],
      "metadata": {
        "id": "VYhSW3Nr395w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting words and to count their number of occurence or repeatation\n",
        "# Count the frequency of each word\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.max_length = 2000000\n",
        "\n",
        "\n",
        "word_freq = Counter(alphabet_words)\n",
        "keyword_freq = Counter(filtered_data)\n",
        "total_keywords = len(filtered_data)\n",
        "print(word_freq)\n",
        "total_word = len(alphabet_words)\n",
        "Total_data = whole_data.split()\n",
        "totalwordcount = len(Total_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "tA9P9E5x6PUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Number of words\n",
        "print(\"Total Number of texts extracted: \", totalwordcount)\n",
        "print(\"Total Number of words:\", total_word)\n",
        "print(\"Total Number of Keywords:\", total_keywords)\n"
      ],
      "metadata": {
        "id": "cB22VQGCKGFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Barchart\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "common_words = keyword_freq.most_common(10)\n",
        "words, frequencies = zip(*common_words)\n",
        "\n",
        "\n",
        "colors = ['darkred', 'violet', 'black', 'magenta', 'lightgreen',\n",
        "          'lightsalmon', 'lightblue', 'lightgray', 'blue', 'yellow']\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.bar(words, frequencies, color=colors)\n",
        "plt.xlabel('Different Words', fontsize=14)\n",
        "plt.ylabel('Frequency', fontsize=14)\n",
        "plt.title('Top 10 Most Common Words', fontsize=16)\n",
        "plt.xticks(rotation=45, fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "\n",
        "\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "\n",
        "for i, v in enumerate(frequencies):\n",
        "    plt.text(i, v, str(v), ha='center', va='bottom', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "la9XFyPC5ZDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the word cloud for the words\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "wordcloud = WordCloud(width=800, height=400).generate(' '.join(keyword_freq))\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sQPOWmzw_pbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the word cloud for keywords\n",
        "word_list=[]\n",
        "for ele in common_words:\n",
        "  word_list=word_list+[ele[0]]\n",
        "\n",
        "wordcloud = WordCloud(width=800, height=400).generate(' '.join(word_list))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZpKn4Mz8_2wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross checking**\n",
        "\n",
        "\n",
        "*   Cross checking was done using another small website containing less number of data (IISER Mohali moodle website)\n"
      ],
      "metadata": {
        "id": "PpG42o3geJzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check_url = \"https://web.iisermohali.ac.in/\"\n",
        "response = requests.get(check_url)\n",
        "check_soup = BeautifulSoup(response.text, 'html.parser')\n",
        "check_data = check_soup.get_text()\n",
        "\n",
        "print(check_data)"
      ],
      "metadata": {
        "id": "JRSAdDQBeMv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_words = check_data.split()\n",
        "wordcount = len(check_words)\n",
        "print(wordcount)"
      ],
      "metadata": {
        "id": "zIoJZHSLeaWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting words and to count their number of occurence or repeatation\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.max_length = 2000000  # Set a higher limit (adjust as needed)\n",
        "new_check_data = check_data.replace(\"\\u200e\",\" \")\n",
        "doc1 = nlp(new_check_data)\n",
        "words = [token.text for token in doc1 if token.is_alpha]\n",
        "#print(words)\n",
        "# Count the frequency of each word\n",
        "word_freq = Counter(words)\n",
        "total_words = len(words)\n",
        "\n",
        "#words = [token.text for token in doc if token.is_alpha]\n",
        "#word_freq = Counter(words)\n",
        "print(words)\n",
        "print(word_freq)\n",
        "print(\"Total Number of Words:\", total_words)"
      ],
      "metadata": {
        "id": "hGPGPGjMfhqJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}